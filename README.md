书生浦语-第二期实战营12班 

L1：《书生浦语大模型全链路开源体系》 By 人工智能实验室陈凯老师 https://www.bilibili.com/video/BV1Vx421X72D/

一、大模型成为发展通用人工智能的重要途径（专用模型→通用大模型）

【专用模型】特定任务，一个模型解决一个问题（2006-2021）语音/图像/人脸识别/德扑...

【通用大模型】一个模型解决多个问题，多种模态（chatgpt/gpt4）

二、书生浦语大模型开源历程（2023.6起)

2023.6.7  InternLM 千亿参数LM发布

2023.7.6 InternLM 升级（8k语境，26种语言） 全面开源、免费商用  InternLM-7B 全链条开源工具体系

2023.8.14 书生万卷1.0--多模态训练语料库开源；

2023.8.21 升级版对话模型InternLM-chat-7B V1.1，开源智能体框架Lagent（支持语言模型到智能体升级转换）

2023.8.28 InternLM千亿参数量升级到123B

2023.9 增强版InternLM-20B开源，开源工具链全栈升级

2024.1  InternLM 2开源

三、书生浦语2.0（InternLM2）的体系

【7B】轻量级 + 【20B】综合级（解决复杂问题）

每个规格鱼油3个版本：IntermLM2-Base、InternLM2（推荐使用）、InternLM2-Chat（共情聊天）

四、InternLM2做了什么事？  回归语言建模的本质

第一代数据清洗过滤技术（多维度数据价值评估→高质量语料推动的数据富集→有针对性地数据补齐）

随着训练数据语料升级，下游任务性能增强

五、InternLM2的主要两点

1. 超长上下文（20万token上下文）
2. 综合性能全面提升（推理、数学、代码 InternLM-20B 重点测评比肩ChatGPT）
3. 对话和创作体验好（AlpacaEval2超越Gpt3.5和Gemini Pro）
4. 工具调用能力整体升级（支持复杂智能体搭建）
5. 突出的数理能力和实用的数据分析功能（GSM8K和Math达到和GPT4相仿水平）
